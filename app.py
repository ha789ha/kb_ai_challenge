from model.retriever import EmbeddingModel
from model.generation import Gpt
from model.queryAnalyze import QueryAnalyzer
from model.finalgen import FinalGen
from model.google import get_google_results,get_keywords_from_query
from model.retrieverCSV import * # ì „ë¬¸ê°€ QA ì¶”ê°€


import base64
import os
import json
import pickle
import uuid
import re
from PyPDF2 import PdfReader
import time
import streamlit as st
from openai import OpenAI

# ëª¨ë¸
embedding = EmbeddingModel()
generation_model = Gpt()
analyzer = QueryAnalyzer()
final_gen = FinalGen()

DB_PATH = "Kb/db/faiss_csv"
CSV_PATH = "Kb/kin_crawling2.csv"

db = CsvQAVectorDB(db_path=DB_PATH)

# í”„ë¡¬í”„íŠ¸
system_prompt = 'ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ë²•ë¥  ì „ë¬¸ê°€ë¡œ ëª¨ë“  ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•˜ë„ë¡ í•˜ì„¸ìš”'

# ìˆ˜ì • 
#def rewrite_query(query):
def rewrite_query(query: str, google_summary: str) -> str:
    rewrite_prompt = f'''
        ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

        ì•„ë˜ì— ì‚¬ìš©ìê°€ ì‘ì„±í•œ ë¯¼ì› ê¸€ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.  
        ì´ ë¯¼ì› ê¸€ì—ì„œ **íŒë¡€ ê²€ìƒ‰ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ Structured Query í˜•íƒœë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.**  
        ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ì§€ì¼œì„œ ì‘ì„±í•˜ì„¸ìš”:

        1. ìƒí™©(Situation): ë¯¼ì›ì´ ë°œìƒí•˜ê²Œ ëœ ë°°ê²½ê³¼ ì‚¬ê±´ ìš”ì•½
        2. ë¬¸ì œ(Problem): ë¯¼ì›ì¸ì´ ê¶ê¸ˆí•´í•˜ëŠ” í•µì‹¬ ìŸì 
        3. ì§ˆë¬¸(Question): íŒë¡€ ê²€ìƒ‰ì„ ìœ„í•œ ëª…í™•í•œ ì§ˆì˜
        4. í‚¤ì›Œë“œ(Keywords): ê²€ìƒ‰ì— í•„ìš”í•œ í•µì‹¬ ìš©ì–´ë“¤ (ì½¤ë§ˆë¡œ êµ¬ë¶„)

        ë¯¼ì› ê¸€:
        """
        {query}
        """
        
        êµ¬ê¸€ ê²€ìƒ‰ ë‚´ìš©:
        """
        {google_summary}
        """

        Output Example:
        1. ìƒí™©(Situation): [ì—¬ê¸°ì— ìƒí™© ìš”ì•½]
        2. ë¬¸ì œ(Problem): [ì—¬ê¸°ì— ë¬¸ì œ ìš”ì•½]
        3. ì§ˆë¬¸(Question): [ì—¬ê¸°ì— íŒë¡€ ê²€ìƒ‰ìš© ì§ˆì˜]
        4. í‚¤ì›Œë“œ(Keywords): [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, ...]

        ì¤‘ìš”: ë‚´ìš© ì¶•ì•½ì´ë‚˜ ëˆ„ë½ ì—†ì´ ë¯¼ì›ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”. ê°ì •ì  í‘œí˜„ì€ ì œì™¸í•˜ê³ , ì‚¬ê±´/ì‚¬ì‹¤/ì§ˆë¬¸ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.


        '''
        
    rewrite_prompt = generation_model.generate(system_prompt, rewrite_prompt)
        
    return rewrite_prompt

def first_generation_prompt(re_query, text):
    prompt = f'''
    ì•„ë˜ì˜ íŒê²°ë¬¸ì€ íšŒì‚¬ì™€ ë¶„ìŸì„ ê²ªê³  ìˆëŠ” ë¯¼ì›ì¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ê²ƒìœ¼ë¡œ ê²€ìƒ‰ëœ íŒë¡€ì™€ ë¯¼ì›ì¸ì˜ ë¯¼ì›ê¸€ì…ë‹ˆë‹¤. 
    ë¯¼ì›ê¸€ì˜ ìƒí™©ê³¼ íŒê²°ë¬¸ì˜ ìƒí™©ì„ ìœ ì‚¬ë„ë¥¼ 0 ~ 100ê¹Œì§€ ì ìˆ˜ë¡œ íŒê²°í•˜ê³  ìœ ì‚¬ì ê³¼ ì°¨ì´ì ì„ ë§í•˜ë„ë¡ í•˜ì„¸ìš”.
    
    
    ## ë¯¼ì›ê¸€
    {re_query}
    
    ## íŒê²°ë¬¸
    {text}

'''
    return prompt

def chat_message(role, content, delay=0.5):
    with st.chat_message(role):
        st.markdown(content)
    time.sleep(delay)
    
    
def render_case_summaries(case_summaries):
    case_cards_html = ""
    for idx, case in enumerate(case_summaries, start=1):
        issue = case.get('ìŸì ', '')
        summary = case.get('ê²°ê³¼ ìš”ì•½', '')
        laws = case.get('ê´€ë ¨ ì•½ê´€ í˜¹ì€ ë²•ë¥ ', [])
        notes = case.get('íŠ¹ì´ ì‚¬í•­', [])

        card_html = f"""
        <div class="case-card">
            <div class="case-card-title">ì‚¬ê±´ {idx}</div>
            <div class="case-section"><strong>âš–ï¸ ìŸì </strong><br>{issue}</div>
            <div class="case-section"><strong>ğŸ“„ ê²°ê³¼ ìš”ì•½</strong><br>{summary}</div>
            </div>
        </div>
        """
        case_cards_html += card_html


    return case_cards_html
    
# ì„¸ì…˜ìƒíƒœì— ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶”ê°€
if 'consideration_idx' not in st.session_state:
    st.session_state.consideration_idx = 0
if 'answers' not in st.session_state:
    st.session_state.answers = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False

# ì´ì „ ëŒ€í™” ë‚´ì—­ ì¶œë ¥
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"], unsafe_allow_html=True)


st.markdown("""
<style>
.case-container {
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
}
.case-card {
    background-color: #f9f9f9;
    border: 1px solid #ddd;
    border-radius: 10px;
    padding: 1rem;
    flex: 1 1 calc(33% - 1rem);
    box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    min-width: 300px;
}
.case-card-title {
    font-size: 1.2rem;
    font-weight: bold;
    margin-bottom: 0.5rem;
    color: #333;
}
.case-section {
    margin-bottom: 0.8rem;
    font-size: 0.95rem;
    line-height: 1.4;
}
.case-section ul {
    margin: 0.3rem 0 0 1.2rem;
    padding: 0;
}
</style>
""", unsafe_allow_html=True)


# ì²« ì§ˆë¬¸ ì…ë ¥ ë°›ê¸°
if not st.session_state.analysis_done:
    if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.chat_message("user").markdown(query)
        st.session_state.chat_history.append({"role": "user", "content": query})
        
        #í‚¤ì›Œë“œ ë°˜ì˜
        keywords = get_keywords_from_query(query,generation_model)
        print(keywords)
        # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼
        google_summary = get_google_results(keywords, num_results=2)
        print(google_summary)

        # Query Rewriting & Case Summary & Analysis (ì‹¤ì œ RAG ì—°ê²° ë¶€ë¶„)
        re_query = rewrite_query(query,google_summary)
        print('---- rewriting ì™„ë£Œ')
        case_summary = embedding.retrieve_json_summaries(re_query)
        
        #ì „ë¬¸ê°€ QA ìŒ ì¶”ê°€
        QA_summary = db.search_top1(re_query)
        print(QA_summary)

        
        analyzer_result = analyzer.analyze_query(query, case_summary[0])
        
        
        if analyzer_result['success']:
            analysis = analyzer_result["analysis"]
            overview = analysis["overview"]
            issues = analysis['issues']
            considerations = analysis['considerations']

        # ìœ ì‚¬ top 3
        combined_html = render_case_summaries(case_summary)
        
        with st.chat_message("assistant"):
            st.markdown(combined_html, unsafe_allow_html=True)

        # chat_historyì— í•œë²ˆì— ì €ì¥
        st.session_state.chat_history.append({"role": "assistant", "content": combined_html})


        # ì²« ê³ ë ¤ì‚¬í•­ ì§ˆë¬¸
        first_consideration = analysis['considerations'][0]
        st.chat_message("assistant").markdown(first_consideration)
        st.session_state.chat_history.append({"role": "assistant", "content": first_consideration})

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        st.session_state.analysis = analysis
        st.session_state.analysis_done = True

# ê³ ë ¤ì‚¬í•­ ë©€í‹°í„´ Q&A ì§„í–‰
elif st.session_state.consideration_idx < len(st.session_state.analysis['considerations']):
    user_reply = st.chat_input("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”")
    if user_reply:
        st.chat_message("user").markdown(user_reply)
        st.session_state.chat_history.append({"role": "user", "content": user_reply})
        st.session_state.answers.append(user_reply)

        st.session_state.consideration_idx += 1
        if st.session_state.consideration_idx < len(st.session_state.analysis['considerations']):
            next_consideration = st.session_state.analysis['considerations'][st.session_state.consideration_idx]
            st.chat_message("assistant").markdown(next_consideration)
            st.session_state.chat_history.append({"role": "assistant", "content": next_consideration})
        else:
            with st.spinner('ëª¨ë“  ê³ ë ¤ì‚¬í•­ ë‹µë³€ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.'):
                user_responses = final_gen.process_user_responses(
                    st.session_state.analysis['considerations'],
                    st.session_state.answers
                )

                result = final_gen.generate_report_only(
                    st.session_state.chat_history[0]['content'],
                    st.session_state.analysis['overview'],
                    st.session_state.analysis,
                    user_responses
                )

                with open('final_report.pdf', 'rb') as file:
                    file_bytes = file.read()
                    
                    
                    
            st.download_button(
                label = 'ìµœì¢… ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ',
                data = file_bytes,
                file_name = 'ìµœì¢…ë³´ê³ ì„œ.pdf',
                mime='application/pdf'
            )
                    
    
    
    
    